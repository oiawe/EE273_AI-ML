{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码运行须知\n",
    "\n",
    "本次项目代码全部在同一个文件中，包含数据集读取、预处理，模型搭建、模型参数调整等，在每段代码前都已标注本段代码的作用。\n",
    "\n",
    "如需具体测试各种数据预处理类型和模型优化的话，请根据每段代码前的注释将对应的代码段**解除注释**，同时保证其他代码段处于**被注释**状态即可。\n",
    "\n",
    "基本的模型(KNN, LogisticRegression)建议一次运行一个，也可以同时运行多个并输出，但此时不保证输出结果的美观。\n",
    "\n",
    "如需更换数据集，只需在Cell 2(第二个方块)中将 pd.read_csv()中的文件名称修改即可。\n",
    "\n",
    "以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# KNN模型构建\n",
    "class KNN():\n",
    "\n",
    "    def __init__(self, x_train, y_train, metric_type): \n",
    "        \"\"\"\n",
    "            此函数为模型初始化函数\n",
    "            输入的参数分别为：\n",
    "            x_train: 输入训练集\n",
    "            y_train: 输入训练集对应的输出训练集\n",
    "            metric_type: 模型选定的范数类型\n",
    "        \"\"\"\n",
    "\n",
    "        self.metric_type = metric_type\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def distance(self, metric_type, p1, p2): \n",
    "        \"\"\"\n",
    "            此函数用于计算两点间的距离\n",
    "            参数metric_type用于确定范数类型\n",
    "        \"\"\"\n",
    "\n",
    "        diff = p1 - p2\n",
    "        if metric_type == \"L1\":\n",
    "            dist = np.sum(abs(diff))\n",
    "\n",
    "        if metric_type == \"L2\":\n",
    "            dist = np.sqrt(np.sum(diff ** 2))\n",
    "        \n",
    "        if metric_type == \"L-inf\":\n",
    "            dist = np.max(abs(diff))\n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def Neighbors(self, K, sample):\n",
    "        \"\"\"\n",
    "            此函数用于遍历训练集中的点并求出最近的K个点\n",
    "            返回值:\n",
    "            K近邻的类型\n",
    "        \"\"\"\n",
    "\n",
    "        dis = np.array([(i, self.distance(self.metric_type, sample, self.x_train[i])) for i in range(len(self.x_train))])\n",
    "        sorted_distance = sorted(dis, key=lambda x: x[1])\n",
    "        neighbors = [self.y_train[int(sorted_distance[i][0])] for i in range(K)]\n",
    "        return neighbors\n",
    "\n",
    "        \n",
    "    def Majority(self ,neighbors):\n",
    "        \"\"\"\n",
    "            此函数将根据K近邻投票判决测试集的类型\n",
    "            输入参数:\n",
    "            neighors:K近邻的类型(已排序)\n",
    "            返回值：\n",
    "            预测结果\n",
    "        \"\"\"\n",
    "        \n",
    "        elements = np.unique(neighbors, return_counts=True)\n",
    "        max_val = np.max(elements[1])\n",
    "        predicted = elements[0][sorted(np.where(elements[1] == max_val)[0])[0]]\n",
    "        return predicted\n",
    "\n",
    "    def predict(self, K, x_test):\n",
    "        \"\"\"\n",
    "            此函数将直接输出模型预测结果\n",
    "            输入参数：\n",
    "            K: KNN中的K\n",
    "            x_test:测试集\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = np.array([self.Majority(self.Neighbors(K, x_test[i])) for i in range(len(x_test))])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "## 读取数据集\n",
    "# csv = pd.read_csv(\"./origin_breast_cancer_data.csv\")  \n",
    "csv = pd.read_csv(\"./breast_cancer_data_357B_100M.csv\")  \n",
    "csv = csv.drop(columns=[\"id\"], axis=1)\n",
    "y = csv[\"diagnosis\"]\n",
    "y = y.replace('B', 0)\n",
    "y = y.replace(\"M\", 1)\n",
    "# x = csv.drop(columns=[\"diagnosis\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Origin数据集剪枝结果\n",
    "# x = csv[[\"texture_mean\", \"concave points_mean\", \n",
    "#         \"area_se\", \"radius_worst\", \n",
    "#         \"texture_worst\", \"perimeter_worst\", \n",
    "#         \"area_worst\", \"smoothness_worst\", \n",
    "#         \"concavity_worst\", \"concave points_worst\"]]\n",
    "\n",
    "\n",
    "# Origin数据集剪枝结果 + 8NN特殊项\n",
    "x = csv[[\"texture_mean\", \"area_mean\", \"concave points_mean\", \n",
    "        \"area_se\", \"radius_worst\", \n",
    "        \"texture_worst\", \"perimeter_worst\", \n",
    "        \"area_worst\", \"smoothness_worst\", \n",
    "        \"concavity_worst\", \"concave points_worst\"]]\n",
    "        \n",
    "\n",
    "# 失衡数据集剪枝结果\n",
    "# x = csv[[\"texture_mean\",  \"fractal_dimension_se\", \n",
    "#         \"symmetry_se\", \"texture_worst\", \n",
    "#         \"perimeter_worst\", \"area_worst\", \n",
    "#         \"smoothness_worst\", \"concave points_worst\"]]\n",
    "\n",
    "stand = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下为各种预处理数据的手段：\n",
    "1. 对数据进行统计学分析并*剔除*不符合$3\\sigma$原则的项(整行消除)\n",
    "\n",
    "2. 对数据进行统计学分析并*替换*不符合$3\\sigma$原则的项，替换公式为$x=|ave_x + rand * standard-variance_x|$，其中$rand \\sim N(0,1)$(添加绝对值是因为所用用到的样本数值均为正数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    删除偏离项\n",
    "'''\n",
    "\n",
    "# i = 0\n",
    "# while i < x.shape[1]:\n",
    "\n",
    "#     ave = np.average(x[:,i])\n",
    "#     var = 0\n",
    "#     j = 0\n",
    "\n",
    "#     for k in range(x.shape[0]):\n",
    "#         var += (x[k, i] - ave) ** 2\n",
    "#     std = np.sqrt(var / (1.0 * x.shape[0]))\n",
    "#     # print(\"ave for: \", ave)\n",
    "#     # print(\"var for: \", std)\n",
    "\n",
    "#     while j < x.shape[0]:\n",
    "#         if x[j,i] < (ave - 3 * std) or x[j,i] > (ave + 3 * std):\n",
    "#             # print(\" 删除元素: \" , i, \" column \", x[j,i])\n",
    "#             x = np.delete(x, j, 0)\n",
    "#             y = np.delete(y, j, 0)\n",
    "#             j = j - 1\n",
    "#             # print(x.shape[0])\n",
    "#         j = j + 1\n",
    "#     i += 1\n",
    "#     # print(\"i \", i)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    修正偏离项\n",
    "'''\n",
    "\n",
    "# i = 0\n",
    "# while i < x.shape[1]:\n",
    "\n",
    "#     ave = np.average(x[:,i])\n",
    "#     var = 0\n",
    "#     j = 0\n",
    "\n",
    "#     for k in range(x.shape[0]):\n",
    "#         var += (x[k, i] - ave) ** 2\n",
    "#     std = np.sqrt(var / (1.0 * x.shape[0]))\n",
    "#     # print(\"ave for: \", ave)\n",
    "#     # print(\"var for: \", std)\n",
    "    \n",
    "#     while j < x.shape[0]:\n",
    "#         if x[j,i] < (ave - 3 * std) or x[j,i] > (ave + 3 * std):\n",
    "#             # print(\"  修改元素: \" , i, \" column \", x[j,i])\n",
    "#             ran = np.random.normal()\n",
    "#             x[j,i] = np.abs(ave + var * ran)\n",
    "#             # print(\"修正后的X值为 \", x[j,i])\n",
    "#         j = j + 1\n",
    "#     i += 1\n",
    "#     # print(\"i \", i)\n",
    "#     # print(\"----------------------\")\n",
    "#     # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   ## 逻辑回归模型\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import warnings\n",
    "\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# Logistic = LogisticRegression()\n",
    "\n",
    "\n",
    "'''\n",
    "    更改分类权重\n",
    "'''\n",
    "Logistic = LogisticRegression(class_weight=\"balanced\")\n",
    "# Logistic = LogisticRegression(class_weight={0:0.2, 1:0.8})\n",
    "\n",
    "\n",
    "'''\n",
    "    正则化回归模型\n",
    "'''\n",
    "# Logistic = LogisticRegression(solver=\"liblinear\",penalty=\"l1\")\n",
    "# Logistic = LogisticRegression(solver=\"liblinear\",penalty=\"l2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for LLR is:  0.9526\n",
      "Average recall for LR is:  0.932\n",
      "Average F1 score for LR  is:  0.894\n",
      "Average Precision for LR is:  0.8633\n",
      "Worst accuracy for LR is:  0.8587\n",
      "Worst recall for LR is:  0.6316\n",
      "Worst F1 score for LR is:  0.6667\n",
      "Worst Precision for LR is:  0.5714\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# import time\n",
    "\n",
    "step = 2000 ## 重复测试次数\n",
    "k_range = 8\n",
    "k_vals = ['L1','L2','L-inf']  ## 范数类型\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    KNN结果初始化\n",
    "'''\n",
    "# ave_accurate = [np.zeros(k_range) for i in range(3)] ## 记录KNN中K从4到12变化评估参数的变化情况\n",
    "# ave_recall = [np.zeros(k_range) for i in range(3)]\n",
    "# ave_precision = [np.zeros(k_range) for i in range(3)]\n",
    "# ave_F1 = [np.zeros(k_range) for i in range(3)]\n",
    "\n",
    "# worst_accurate = [np.ones(k_range) for i in range(3)]\n",
    "# worst_recall = [np.ones(k_range) for i in range(3)]\n",
    "# worst_precision = [np.ones(k_range) for i in range(3)]\n",
    "# worst_F1 = [np.ones(k_range) for i in range(3)]\n",
    "\n",
    "\n",
    "'''\n",
    "    8NN结果初始化\n",
    "'''\n",
    "ave_accurate = 0 \n",
    "ave_recall = 0\n",
    "ave_precision = 0\n",
    "ave_F1 = 0\n",
    "\n",
    "worst_accurate = 1\n",
    "worst_recall = 1\n",
    "worst_precision = 1\n",
    "worst_F1 = 1\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    逻辑回归结果初始化\n",
    "'''  \n",
    "aveLogScore = 0\n",
    "aveLogRecall = 0\n",
    "aveLogF1 = 0\n",
    "aveLogPrecision = 0\n",
    "\n",
    "wLS = 1\n",
    "wLR = 1\n",
    "wLF = 1\n",
    "wLP = 1\n",
    "\n",
    "\n",
    "# importance = np.zeros(30)\n",
    "\n",
    "\n",
    "'''\n",
    "    模型训练与结果预测\n",
    "'''  \n",
    "# begin = time.time()\n",
    "for i in range(step):    \n",
    "\n",
    "    # 数据集分割\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = sklearn.model_selection.train_test_split(x, y, test_size=0.2)  ## 数据集分割，其中20%为测试集，80%为训练集\n",
    "    # 修改数据类型用于模型运算\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "        逻辑回归模型训练与预测\n",
    "    '''  \n",
    "    Logistic.fit(train_x, train_y)\n",
    "    Logy_pred = Logistic.predict(test_x)\n",
    "\n",
    "\n",
    "    LogScore = accuracy_score(y_true = test_y, y_pred = Logy_pred)\n",
    "    LogRecall = recall_score(y_true = test_y, y_pred = Logy_pred)\n",
    "    LogF1 = f1_score(y_true = test_y, y_pred = Logy_pred)\n",
    "    LogPrecision = precision_score(y_true = test_y, y_pred = Logy_pred)\n",
    "\n",
    "    aveLogScore += LogScore\n",
    "    aveLogF1 += LogF1\n",
    "    aveLogRecall += LogRecall\n",
    "    aveLogPrecision += LogPrecision\n",
    "\n",
    "    if wLS > LogScore:\n",
    "        wLS = LogScore\n",
    "    \n",
    "    if wLR > LogRecall:\n",
    "        wLR = LogRecall\n",
    "    \n",
    "    if wLF > LogF1:\n",
    "        wLF = LogF1\n",
    "    \n",
    "    if wLP > LogPrecision:\n",
    "        wLP = LogPrecision\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "        KNN模型训练与预测\n",
    "    '''  \n",
    "    # for k in range(1, k_range + 1):\n",
    "    #     for j in range(len(k_vals)):\n",
    "    #         knn = KNN(train_x, train_y, k_vals[j])\n",
    "    #         KNNy_pred = knn.predict(k + 3, test_x)\n",
    "\n",
    "    #         result = np.zeros(4) # 按顺序记录TP TN FP FN\n",
    "    #         for l in range(len(test_y)):\n",
    "    #             if test_y[l] == 1 and KNNy_pred[l] == 1: # 预测为正且预测正确 TP\n",
    "    #                 result[0] += 1 \n",
    "    #             elif test_y[l] == 0 and KNNy_pred[l] == 0: # 预测为负且预测正确 TN\n",
    "    #                 result[1] += 1\n",
    "    #             elif test_y[l] == 0 and KNNy_pred[l] == 1: # 预测为正但预测错误 FP\n",
    "    #                 result[2] += 1\n",
    "    #             elif test_y[l] == 1 and KNNy_pred[l] == 0: # 预测为负但预测错误 FN\n",
    "    #                 result[3] += 1\n",
    "\n",
    "    #         recall = (1.0 * result[0]) / (result[0] + result[3])\n",
    "    #         precision = (1.0 * result[0]) / (result[0] + result[2])\n",
    "    #         F1 = 2.0 * (recall * precision) / (recall + precision)\n",
    "    #         KNNScore = np.sum(test_y == KNNy_pred) / len(test_y)\n",
    "            \n",
    "    #         # print(\"Accuracy for LogisticRegresion is: \", LogScore)\n",
    "    #         ave_accurate[j][k-1] += KNNScore\n",
    "    #         ave_recall[j][k-1] += recall\n",
    "    #         ave_precision[j][k-1] += precision\n",
    "    #         ave_F1[j][k-1] += F1\n",
    "\n",
    "    #         if KNNScore < worst_accurate[j][k-1]:\n",
    "    #             worst_accurate[j][k-1] = KNNScore\n",
    "\n",
    "    #         if recall < worst_recall[j][k-1]:\n",
    "    #             worst_recall[j][k-1] = recall\n",
    "            \n",
    "    #         if precision < worst_precision[j][k-1]:\n",
    "    #             worst_precision[j][k-1] = precision\n",
    "            \n",
    "    #         if F1 < worst_F1[j][k-1]:\n",
    "    #             worst_F1[j][k-1] = F1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "        8NN模型训练与预测\n",
    "    '''  \n",
    "    # knn = KNN(train_x, train_y, \"L2\")\n",
    "    # KNNy_pred = knn.predict(8, test_x)\n",
    "\n",
    "    # result = np.zeros(4) # 按顺序记录TP TN FP FN\n",
    "    # for l in range(len(test_y)):\n",
    "    #     if test_y[l] == 1 and KNNy_pred[l] == 1: # 预测为正且预测正确 TP\n",
    "    #         result[0] += 1 \n",
    "    #     elif test_y[l] == 0 and KNNy_pred[l] == 0: # 预测为负且预测正确 TN\n",
    "    #         result[1] += 1\n",
    "    #     elif test_y[l] == 0 and KNNy_pred[l] == 1: # 预测为正但预测错误 FP\n",
    "    #         result[2] += 1\n",
    "    #     elif test_y[l] == 1 and KNNy_pred[l] == 0: # 预测为负但预测错误 FN\n",
    "    #         result[3] += 1\n",
    "\n",
    "    # recall = (1.0 * result[0]) / (result[0] + result[3])\n",
    "    # precision = (1.0 * result[0]) / (result[0] + result[2])\n",
    "    # F1 = 2.0 * (recall * precision) / (recall + precision)\n",
    "    # KNNScore = np.sum(test_y == KNNy_pred) / len(test_y)\n",
    "            \n",
    "    # # print(\"Accuracy for LogisticRegresion is: \", LogScore)\n",
    "    # ave_accurate += KNNScore\n",
    "    # ave_recall += recall\n",
    "    # ave_precision += precision\n",
    "    # ave_F1 += F1\n",
    "\n",
    "    # if KNNScore < worst_accurate:\n",
    "    #     worst_accurate = KNNScore\n",
    "\n",
    "    # if recall < worst_recall:\n",
    "    #     worst_recall = recall\n",
    "            \n",
    "    # if precision < worst_precision:\n",
    "    #     worst_precision = precision\n",
    "            \n",
    "    # if F1 < worst_F1:\n",
    "    #     worst_F1 = F1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "        决策树辅助测试\n",
    "    '''  \n",
    "#     model = DecisionTreeClassifier()\n",
    "#     model.fit(train_x,train_y) \n",
    "#     y_pre = model.predict(test_x)\n",
    "#     mScore = accuracy_score(y_true=test_y, y_pred=y_pre)\n",
    "#     importance += model.feature_importances_\n",
    "\n",
    "\n",
    "# importance = importance / step\n",
    "# print(\"Importance for each attributes:\")\n",
    "# print(importance)\n",
    "# for i in range(len(importance)):\n",
    "#     if importance[i]> 0.005:\n",
    "#         print(\"The most important attribute is: \", i + 1)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    逻辑回归结果输出\n",
    "'''  \n",
    "print(\"Average accuracy for LLR is: \", round(aveLogScore / step, 4))            \n",
    "print(\"Average recall for LR is: \", round(aveLogRecall / step, 4))\n",
    "print(\"Average F1 score for LR  is: \", round(aveLogF1 / step, 4))\n",
    "print(\"Average Precision for LR is: \", round(aveLogPrecision / step, 4))\n",
    "\n",
    "print(\"Worst accuracy for LR is: \", round(wLS, 4))            \n",
    "print(\"Worst recall for LR is: \", round(wLR, 4))\n",
    "print(\"Worst F1 score for LR is: \", round(wLF, 4))\n",
    "print(\"Worst Precision for LR is: \", round(wLP, 4))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    8NN结果输出\n",
    "'''  \n",
    "# print(\"Average accuracy for 8NN is: \", round(ave_accurate / step, 4))            \n",
    "# print(\"Average recall for 8NN is: \", round(ave_recall / step, 4))\n",
    "# print(\"Average F1 score for 8NN is: \", round(ave_F1 / step, 4))\n",
    "# print(\"Average Precision for 8NN is: \", round(ave_precision / step, 4))\n",
    "\n",
    "# print(\"Worst accuracy for 8NN is: \", round(worst_accurate, 4))            \n",
    "# print(\"Worst recall for 8NN is: \", round(worst_recall, 4))\n",
    "# print(\"Worst F1 score for 8NN is: \", round(worst_F1, 4))\n",
    "# print(\"Worst Precision for 8NN is: \", round(worst_precision, 4))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    KNN结果输出\n",
    "'''\n",
    "# for i in range(3):\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Average accuracy for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = ave_accurate[i] / (1.0 * step)\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Worst accuracy for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = worst_accurate[i]\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Average recall for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = ave_recall[i] / (1.0 * step)\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Worst recall for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = worst_recall[i]\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Average precision for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = ave_precision[i] / (1.0 * step)\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Worst precision for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = worst_precision[i]\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Average F1 score for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = ave_F1[i] / (1.0 * step)\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()    \n",
    "\n",
    "    # plt.figure()\n",
    "    # str = \"Worst F1 score for \" + k_vals[i]\n",
    "    # plt.title('%s'%str)\n",
    "    # accur = worst_F1[i]\n",
    "    # axis = np.arange(4, k_range + 4)\n",
    "    # plt.plot(axis,accur)\n",
    "    # plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe72f31d202ac886a01e3e509391b989acd0ec7a1d278014806771e3124778bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
